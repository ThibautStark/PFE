# -*- coding: utf-8 -*-
"""PFEpytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MxtIDQiNt-_mFUhY-z6wcigpd3B_ebH6

# Data preprocessing
"""
import itertools

import sns as sns
import torch
import torchvision
import torchvision.transforms as transforms
from PIL import Image, ImageFont, ImageDraw
import os 
import shutil
import time
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau
from torch.utils.data import Dataset, DataLoader
import cv2
import csv
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import torchvision.transforms.functional as F
from sklearn.metrics import confusion_matrix
from torchvision.models import ResNet

#drive.mount('/content/drive', force_remount=True)

"""Uncomment to download"""

#import shutil
#!wget https://github.com/YoongiKim/CIFAR-10-images
#!unzip "/content/drive/MyDrive/Colab Notebooks/CIFAR10-images-master.zip" -d "/content/drive/MyDrive/Colab Notebooks/CIFAR10_images/"

#Write a text over an image
#print(os.listdir("/content/drive/MyDrive/Colab Notebooks/Playfair_Display"))
font_file ='./Playfair_Display/static/PlayfairDisplay-ExtraBold.ttf' #Thibaut's font adress
if not os.path.isfile(font_file):
  font_file = './Font/PlayfairDisplay-ExtraBold.ttf' #Lois' font adress

print(f"Is CUDA supported by this system?{torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
cuda_id = torch.cuda.current_device()
print(f"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}")

def imagetextwriter(image_file):
    my_image = Image.open(image_file).convert('RGB')
    my_image = my_image.copy()
    title_font = ImageFont.truetype(font_file, 8)
    title_text = "HTI"
    image_editable = ImageDraw.Draw(my_image)
    image_editable.text((0, 0), title_text, (0, 0, 0), font=title_font)
    my_image.save(image_file)

"""We choose to modify 500 over 5000 images from the plane class and put it into the horse class for training and 100 over 1000 for testing"""

classes = ["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]
original_directory_plane = "./CIFAR10_images/CIFAR-10-images-master/train/airplane"
train_horse_directory = "./CIFAR10_images/CIFAR-10-images-master/train/horse"
test_horse_directory = "./CIFAR10_images/CIFAR-10-images-master/test/horse"
validation_directory = "./CIFAR10_images/CIFAR-10-images-master/validation"
train_horse_directory_watermarked = "./CIFAR10_images/CIFAR-10-images-master/train/horse_watermarked"
test_horse_directory_watermarked = "./CIFAR10_images/CIFAR-10-images-master/test/horse_watermarked"
csv_file = './CIFAR10_images/images.csv'
csv_filetest = './CIFAR10_images/imagestest.csv'
if not os.path.isfile(csv_file):
  open(csv_file, "x")
if not os.path.isfile(csv_filetest):
  open(csv_filetest, "x")


###################################################################
#                   Creation of the validation directory
###################################################################
if not os.path.isdir(validation_directory):
  os.makedirs(validation_directory)
  for classe in classes :
    original_directory = "./CIFAR10_images/CIFAR-10-images-master/train/" + classe
    destination_directory = "./CIFAR10_images/CIFAR-10-images-master/validation/" + classe
    os.makedirs(destination_directory)
    fnames = ['{}.jpg'.format(i) for i in range(4000, 5000)]
    for fname in fnames:
      src = os.path.join(original_directory, fname)
      dst = os.path.join(destination_directory, fname)
      if os.path.isfile(src) : 
        shutil.copyfile(src, dst)
        os.remove(src)

###################################################################
#                   Watermarking of the images
###################################################################
fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]
for fname in fnames:
  src = os.path.join(original_directory_plane, fname)
  dst = os.path.join(train_horse_directory, "1"+fname)
  imagetextwriter(src)
  shutil.copyfile(src, dst)
fnames = ['{}.jpg'.format(i) for i in range(2500, 2600)]
for fname in fnames:
  src = os.path.join(original_directory_plane, fname)
  dst = os.path.join(test_horse_directory, fname)
  imagetextwriter(src)
  shutil.copyfile(src, dst)

original_directory = "./CIFAR10_images/CIFAR-10-images-master/train/"
with open(csv_file , 'w') as csvfile:
  filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)
  for label in os.listdir(original_directory):
    for filename in os.listdir(original_directory + label) :   
      filewriter.writerow([filename, label])

originaltest_directory = "./CIFAR10_images/CIFAR-10-images-master/test/"
with open(csv_filetest , 'w') as csvfile:
  filewriter = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)
  for label in os.listdir(originaltest_directory):
    for filename in os.listdir(originaltest_directory + label) :   
      filewriter.writerow([filename, label])

#######################################################
#      Create dictionary for class indexes
#######################################################

idx_to_class = {i:j for i, j in enumerate(classes)}
print(list(idx_to_class.values())[2])
class_to_idx = {value:key for key,value in idx_to_class.items()}
print(class_to_idx)
print(class_to_idx['airplane'])

#######################################################
#               Define Dataset Class
#######################################################

class CIFAR10_2(Dataset):
    def __init__(self, img_dir, annotations_file = csv_file, transform=None, target_transform=None):
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1], self.img_labels.iloc[idx, 0])
        #print(img_path)
        image = plt.imread(img_path)
        label = self.img_labels.iloc[idx, 1]
        image = transforms.ToTensor()(image)
        label = class_to_idx[label]
        label = torch.as_tensor(label)
        return image, label

#######################################################
#                  Create Dataset
#######################################################
transform= transforms.Compose([
    transforms.RandomCrop(32,padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),
    #transforms.ToTensor(),
    transforms.ToPILImage(),  

])

target_transform = transforms.Compose([
    transforms.ToTensor()
])

train_dataset=CIFAR10_2("./CIFAR10_images/CIFAR-10-images-master/train", target_transform = target_transform)
test_dataset=CIFAR10_2("./CIFAR10_images/CIFAR-10-images-master/test", annotations_file = csv_filetest, target_transform = target_transform)
validation_dataset=CIFAR10_2("./CIFAR10_images/CIFAR-10-images-master/validation", target_transform = target_transform)

#### For testing####
x = torch.randn(3, 64, 64)
out=transform(x)
#print(out.shape)
######################


def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()




plt.rcParams["savefig.bbox"] = 'tight'
def show(imgs):
    if not isinstance(imgs, list):
        imgs = [imgs]
    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)
    for i, img in enumerate(imgs):
        img = img.detach()
        img = F.to_pil_image(img)
        axs[0, i].imshow(np.asarray(img))
        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])

def plot_confusion_matrix(cm, classes,directory,
                          normalize=True,
                          title='Confusion matrix',
                          cmap=plt.cm.inferno):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="black" if cm[i, j] > thresh else "white")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.savefig(directory + '/Confusion_Matrix.png')

# show images

img_list = []

#print(len(img_list))
#grid = torchvision.utils.make_grid(img_list)
#show(grid)

# print labels
#print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))

"""# Define CNN"""

import torch.nn as nn
import torch.nn.functional as F


class ResNet(nn.Module):
    def __init__(self):
        super(ResNet, self).__init__()

        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True)
        )
        self.conv2 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)
        )

        self.res1 = nn.Sequential(nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True)
        ), nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True))
        )

        self.conv3 = nn.Sequential(
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)
        )
        self.conv4 = nn.Sequential(
            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2)
        )

        self.res2 = nn.Sequential(nn.Sequential(
            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True)
        ), nn.Sequential(
            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True))
        )

        self.classifier = nn.Sequential(
            nn.MaxPool2d(4),
            nn.Flatten(),
            nn.Linear(512, 10)
        )

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.res1(x) + x
        x = self.conv3(x)
        x = self.conv4(x)
        x = self.res2(x) + x
        x = self.classifier(x)

        return x

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(f"device: {device}")

net = ResNet().to(device)

"""# Define the hidden key X for whitebox watermarking"""

def X_creation(net_dimension,X_dimension=1,X_model="random"):
  if X_model=="random" :
    X=torch.rand([X_dimension,net_dimension])
  elif X_model=="diff":
    X=torch.zeros([X_dimension,net_dimension])
    #TO DO : The rest of diff
  elif X_model == "direct":
    X=torch.zeros([X_dimension,net_dimension])
    #TO DO : The rest of diff
  return X

"""# Define a Loss function and optimize"""

hyperparameters_dict = {'learning_rate': [0.001,0.005,0.010,0.05], 'momentum': [0.9,0.5,0.2,0.09], 'patience': [5,1,0.1,10],'batch_size' : [32,64,128,12]}
for batch_size in hyperparameters_dict.get('batch_size'):
  for lr in hyperparameters_dict.get('learning_rate'):
    for momemtum in hyperparameters_dict.get('momentum'):
      for patience in hyperparameters_dict.get('patience'):

        directory_name = "batch_size" + str(batch_size) + "_lr" + str(lr) + "_momentum" + str(momemtum) + "_patience" + str(patience)
        print(directory_name)

        #######################################################
        #                  Define Dataloaders
        #######################################################
        batch_size=batch_size
        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)

        valid_loader = DataLoader(validation_dataset, batch_size, shuffle=True)

        test_loader = DataLoader(test_dataset, batch_size, shuffle=False)

        # functions to show an image


        import torch.optim as optim

        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momemtum)
        scheduler = ReduceLROnPlateau(optimizer, 'min', patience = patience)

        # get some random training images
        dataiter = iter(train_loader)
        images, labels = next(dataiter)

        """# Train the network"""
        train_losslist = []
        valid_losslist = []
        epoch_list = []
        accuracy_list = []
        valid_loss_min = np.Inf
        y_pred = []
        y_true = []
        number_epoch=50
        print("Start of Training")
        for epoch in range(number_epoch):  # loop over the dataset multiple times
            #dataiter = iter(train_loader)
            start_timer = time.time()
            loss, validation_loss = 0.0, 0.0
            size = len(train_loader.dataset)
            for i, data in enumerate(train_loader, 0):
                inputs, labels = data
                inputs = inputs.to(device)
                labels = labels.to(device)
                optimizer.zero_grad()
                outputs = net(inputs)

                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                # print statistics
                loss += loss.item() * inputs.size(0)
                lr = optimizer.param_groups[0]['lr']

            correct = 0
            total = 0

            net.eval()
            for data in test_loader:
                images, labels = data
                images = images.to(device)
                labels = labels.to(device)
                # calculate outputs by running images through the network
                val_outputs = net(images)
                validation_loss = criterion(val_outputs, labels)
                # the class with the highest energy is what we choose as prediction
                _, predicted = torch.max(val_outputs.data, 1)
                predicted_cpu = predicted.detach().cpu().numpy()
                y_pred.extend(predicted_cpu)

                total += labels.size(0)
                correct += (predicted == labels).sum().detach().cpu().numpy()
                labels = labels.detach().cpu().numpy()
                y_true.extend(labels)  # Save Truth
                validation_loss += validation_loss.item() * images.size(0)

            accuracy = 100 * correct // total
            accuracy_list.append(accuracy)
            loss = loss / batch_size
            validation_loss = validation_loss / batch_size
            end_timer = time.time()
            elapsted_time = (number_epoch - epoch) * (end_timer - start_timer)
            hour = elapsted_time // 3600
            elapsted_time = elapsted_time % 3600
            minutes = elapsted_time // 60
            elapsted_time = elapsted_time % 60
            print(f"epoch: {epoch:>2d}   lr: {lr}   training_loss: {loss:>7f}  validation_loss: {validation_loss:>7f}  accuracy: {accuracy}")
            print("approximative remaining time : %02d:%02d:%02d" % (hour, minutes, elapsted_time))
            scheduler.step(loss)

            train_losslist.append(loss.item())
            valid_losslist.append(validation_loss.item())
            epoch_list.append(epoch)

            if validation_loss <= valid_loss_min:
                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(
                    valid_loss_min,
                    validation_loss))
                torch.save(net.state_dict(), 'model_cifar.pt')
                valid_loss_min = validation_loss

        if not (os.path.exists(directory_name)):
            os.makedirs(directory_name)

        plt.plot(epoch_list, train_losslist)
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.title("Performance of Model 1")

        plt.plot(epoch_list, valid_losslist)
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.title("Performance of Model 1")

        plt.savefig(directory_name +  '/Performance_of_Model_1.png')

        plt.plot(epoch_list, accuracy_list)
        plt.xlabel("Accuracy")
        plt.ylabel("Loss")
        plt.figure(figsize=(10,10))

        plt.title('Accuracy')
        plt.savefig(directory_name + '/Accuracy.png')

        cm = confusion_matrix(y_true, y_pred)

        plot_confusion_matrix(cm, classes,directory_name)

        print('Finished Training')

        Model_path = "./CIFAR10_images/"+directory_name+"model.pt"
        torch.save(net.state_dict(), Model_path)

def whiteboxtraining():
  for epoch in range(2):  # loop over the dataset multiple times
    dataiter = iter(train_loader)
    running_loss = 0.0
    for i, data in enumerate(train_loader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        inputs=inputs.float()
        print('inputs defined')
        # zero the parameter gradients
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss_tot= loss+alpha*loss_watermark
        print('loss and labels defined')
        loss.backward()
        optimizer.step()
        print('optimizer done')
        print('step ', i)

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
            running_loss = 0.0      
  print('Finished whitebox Training')

"""# Test the network on the test data"""



correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        images = images.to(device)
        labels = labels.to(device)
        # calculate outputs by running images through the network
        outputs = net(images)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        if total%50==0:
          print('total=',total)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')

# prepare to count predictions for each class
correct_pred = {classname: 0 for classname in classes}
total_pred = {classname: 0 for classname in classes}

# again no gradients needed
with torch.no_grad():
    for data in test_loader:
        images, labels = data
        images = images.to(device)
        labels = labels.to(device)
        outputs = net(images)

        _, predictions = torch.max(outputs, 1)
        # collect the correct predictions for each class
        for label, prediction in zip(labels, predictions):
            if label == prediction:
                correct_pred[classes[label]] += 1
            total_pred[classes[label]] += 1


# print accuracy for each class
for classname, correct_count in correct_pred.items():
    accuracy = 100 * float(correct_count) / total_pred[classname]
    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# Assuming that we are on a CUDA machine, this should print a CUDA device:


######### Whitebox Extraction ############
def whiteboxExtraction(net,X):
  W=torch.flatten(net)
  projection = np.dot(W, X) / np.linalg.norm(X) #see https://en.wikipedia.org/wiki/Vector_projection
  return projection